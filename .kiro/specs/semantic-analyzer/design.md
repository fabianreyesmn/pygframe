# Design Document - Semantic Analyzer

## Overview

The semantic analyzer is designed as the third phase of the PyGFrame compiler, building upon the existing lexical and syntactic analyzers. It processes the Abstract Syntax Tree (AST) generated by the syntactic analyzer to perform type checking, symbol table construction, and semantic error detection. The design follows a visitor pattern approach for AST traversal and integrates seamlessly with the existing GUI framework.

## Architecture

### Core Components

1. **SemanticAnalyzer**: Main orchestrator class that coordinates the semantic analysis process
2. **SymbolTable**: Manages identifier declarations, scopes, and lookups
3. **TypeSystem**: Handles type checking, inference, and conversion rules
4. **ErrorReporter**: Collects and formats semantic errors
5. **ASTAnnotator**: Adds semantic attributes to AST nodes
6. **SemanticVisitor**: Implements visitor pattern for AST traversal

### Integration Points

- **Input**: AST from `sintactico.py` module
- **Dependencies**: `lexico.py` for token types, `pygframe.py` for GUI integration
- **Output**: Annotated AST, symbol table, and error reports
- **File I/O**: Reads TestSemantica.txt, writes semantic analysis results

## Components and Interfaces

### SemanticAnalyzer Class

```python
class SemanticAnalyzer:
    def __init__(self, ast, tokens=None)
    def analyze() -> Tuple[AnnotatedAST, SymbolTable, List[SemanticError]]
    def get_symbol_table() -> SymbolTable
    def get_errors() -> List[SemanticError]
    def format_results() -> str
```

### SymbolTable Class

```python
class SymbolTable:
    def __init__(self)
    def enter_scope(scope_name: str)
    def exit_scope()
    def declare_variable(name: str, type_info: TypeInfo, line: int, column: int)
    def lookup_variable(name: str) -> Optional[SymbolEntry]
    def is_declared(name: str) -> bool
    def get_current_scope() -> str
    def to_formatted_table() -> str
```

### TypeSystem Class

```python
class TypeSystem:
    def get_type(node: ASTNode) -> TypeInfo
    def check_compatibility(type1: TypeInfo, type2: TypeInfo) -> bool
    def can_convert(from_type: TypeInfo, to_type: TypeInfo) -> bool
    def perform_conversion(value, from_type: TypeInfo, to_type: TypeInfo)
    def get_operation_result_type(op: str, left_type: TypeInfo, right_type: TypeInfo) -> TypeInfo
```

### ErrorReporter Class

```python
class ErrorReporter:
    def __init__(self)
    def add_error(error_type: str, message: str, line: int, column: int)
    def has_errors() -> bool
    def get_errors() -> List[SemanticError]
    def format_errors() -> str
```

## Data Models

### TypeInfo

```python
@dataclass
class TypeInfo:
    base_type: str  # 'int', 'float', 'void', 'boolean'
    is_array: bool = False
    array_size: Optional[int] = None
    
    def is_numeric(self) -> bool
    def is_compatible_with(self, other: 'TypeInfo') -> bool
```

### SymbolEntry

```python
@dataclass
class SymbolEntry:
    name: str
    type_info: TypeInfo
    scope: str
    line: int
    column: int
    memory_address: Optional[int] = None
    is_initialized: bool = False
```

### SemanticError

```python
@dataclass
class SemanticError:
    error_type: str
    message: str
    line: int
    column: int
    severity: str = 'error'  # 'error', 'warning'
```

### AnnotatedASTNode

```python
class AnnotatedASTNode(Nodo):
    def __init__(self, original_node: Nodo)
    
    # Semantic attributes
    semantic_type: Optional[TypeInfo] = None
    semantic_value: Optional[Any] = None
    symbol_ref: Optional[SymbolEntry] = None
```

## Error Handling

### Error Categories

1. **Undeclared Variables**: Variables used without declaration
2. **Duplicate Declarations**: Multiple declarations of same identifier in scope
3. **Type Incompatibility**: Operations between incompatible types
4. **Invalid Conversions**: Attempted conversions that are not allowed
5. **Operator Misuse**: Using operators with inappropriate operands

### Error Recovery Strategy

- Continue analysis after non-fatal errors
- Assume reasonable types for undeclared variables to enable further checking
- Report multiple errors in single pass when possible
- Provide clear error messages with line and column information

## Testing Strategy

### Unit Testing Approach

- Test each component independently (SymbolTable, TypeSystem, ErrorReporter)
- Mock AST nodes for isolated testing
- Verify error detection accuracy
- Test type compatibility and conversion rules

### Integration Testing

- Use TestSemantica.txt for comprehensive validation
- Verify correct symbol table construction
- Ensure proper error reporting for known issues
- Test GUI integration with existing tabs

### Expected Test Results

Based on TestSemantica.txt analysis:
- **Undeclared variable errors**: `suma` (line 4), `mas` (line 28, 33)
- **Type incompatibility errors**: `x = 32.32` (assigning float to int)
- **Valid operations**: All arithmetic expressions should type-check correctly
- **Symbol table entries**: All declared variables (x, y, z, a, b, c) with correct types

## Implementation Flow

### Phase 1: AST Traversal and Symbol Collection
1. Traverse AST to identify variable declarations
2. Build symbol table with scope management
3. Detect duplicate declarations

### Phase 2: Type Analysis and Annotation
1. Assign types to all expressions and variables
2. Annotate AST nodes with semantic information
3. Perform type compatibility checking

### Phase 3: Error Detection and Reporting
1. Check for undeclared variable usage
2. Validate type compatibility in assignments and operations
3. Generate comprehensive error reports

### Phase 4: Output Generation
1. Format symbol table for display
2. Create annotated AST representation
3. Generate error reports for GUI display

## GUI Integration

### Tab Updates
- **Semántico Tab**: Display annotated AST and analysis summary
- **Hash Table Tab**: Show formatted symbol table
- **Errores Semánticos Tab**: List all semantic errors with locations

### File Output
- Save symbol table to text file
- Export semantic errors to error log
- Maintain compatibility with existing file I/O patterns

## Performance Considerations

- Single-pass analysis for efficiency
- Lazy evaluation of type information where possible
- Efficient symbol table lookups using hash-based storage
- Minimal memory overhead for AST annotations

## Extensibility

The design supports future enhancements:
- Additional primitive types (string, char)
- Function declarations and calls
- Array and pointer support
- Advanced type inference
- Optimization hints for code generation